{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4b31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9afa672",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sal.json') as json_file:\n",
    "    sal = pd.read_json('sal.json')\n",
    "    twitter = pd.read_json('twitter-data-small.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e1366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbotsbury</th>\n",
       "      <th>abbotsford (nsw)</th>\n",
       "      <th>acacia gardens</th>\n",
       "      <th>agnes banks</th>\n",
       "      <th>airds</th>\n",
       "      <th>alexandria</th>\n",
       "      <th>alfords point</th>\n",
       "      <th>alison (central coast - nsw)</th>\n",
       "      <th>allambie heights</th>\n",
       "      <th>allawah</th>\n",
       "      <th>...</th>\n",
       "      <th>weetangera</th>\n",
       "      <th>weston (act)</th>\n",
       "      <th>whitlam</th>\n",
       "      <th>wright</th>\n",
       "      <th>yarralumla</th>\n",
       "      <th>christmas island</th>\n",
       "      <th>home island</th>\n",
       "      <th>jervis bay</th>\n",
       "      <th>norfolk island</th>\n",
       "      <th>west island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ste</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcc</th>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>1gsyd</td>\n",
       "      <td>...</td>\n",
       "      <td>8acte</td>\n",
       "      <td>8acte</td>\n",
       "      <td>8acte</td>\n",
       "      <td>8acte</td>\n",
       "      <td>8acte</td>\n",
       "      <td>9oter</td>\n",
       "      <td>9oter</td>\n",
       "      <td>9oter</td>\n",
       "      <td>9oter</td>\n",
       "      <td>9oter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sal</th>\n",
       "      <td>10002</td>\n",
       "      <td>10003</td>\n",
       "      <td>10014</td>\n",
       "      <td>10021</td>\n",
       "      <td>10022</td>\n",
       "      <td>10030</td>\n",
       "      <td>10031</td>\n",
       "      <td>10034</td>\n",
       "      <td>10036</td>\n",
       "      <td>10038</td>\n",
       "      <td>...</td>\n",
       "      <td>80132</td>\n",
       "      <td>80133</td>\n",
       "      <td>80134</td>\n",
       "      <td>80135</td>\n",
       "      <td>80136</td>\n",
       "      <td>90001</td>\n",
       "      <td>90002</td>\n",
       "      <td>90003</td>\n",
       "      <td>90004</td>\n",
       "      <td>90005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 15340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abbotsbury abbotsford (nsw) acacia gardens agnes banks  airds alexandria  \\\n",
       "ste          1                1              1           1      1          1   \n",
       "gcc      1gsyd            1gsyd          1gsyd       1gsyd  1gsyd      1gsyd   \n",
       "sal      10002            10003          10014       10021  10022      10030   \n",
       "\n",
       "    alfords point alison (central coast - nsw) allambie heights allawah  ...  \\\n",
       "ste             1                            1                1       1  ...   \n",
       "gcc         1gsyd                        1gsyd            1gsyd   1gsyd  ...   \n",
       "sal         10031                        10034            10036   10038  ...   \n",
       "\n",
       "    weetangera weston (act) whitlam wright yarralumla christmas island  \\\n",
       "ste          8            8       8      8          8                9   \n",
       "gcc      8acte        8acte   8acte  8acte      8acte            9oter   \n",
       "sal      80132        80133   80134  80135      80136            90001   \n",
       "\n",
       "    home island jervis bay norfolk island west island  \n",
       "ste           9          9              9           9  \n",
       "gcc       9oter      9oter          9oter       9oter  \n",
       "sal       90002      90003          90004       90005  \n",
       "\n",
       "[3 rows x 15340 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c753cc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abbotsbury          1gsyd\n",
       "abbotsford (nsw)    1gsyd\n",
       "acacia gardens      1gsyd\n",
       "agnes banks         1gsyd\n",
       "airds               1gsyd\n",
       "                    ...  \n",
       "christmas island    9oter\n",
       "home island         9oter\n",
       "jervis bay          9oter\n",
       "norfolk island      9oter\n",
       "west island         9oter\n",
       "Name: gcc, Length: 15340, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal.loc[\"gcc\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f1075e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_rev</th>\n",
       "      <th>data</th>\n",
       "      <th>includes</th>\n",
       "      <th>matching_rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1412193387575316480</td>\n",
       "      <td>2-0fa70896c4b97c5fa391af1b9ea8e0d1</td>\n",
       "      <td>{'author_id': '836119507173154816', 'conversat...</td>\n",
       "      <td>{'places': [{'full_name': 'Australia', 'geo': ...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1412195752344883200</td>\n",
       "      <td>1-1f2c1ed1b6971974f6cf160432cf5cd3</td>\n",
       "      <td>{'author_id': '1399941819950006272', 'conversa...</td>\n",
       "      <td>{'places': [{'full_name': 'Australia', 'geo': ...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1412189452361891840</td>\n",
       "      <td>2-b7051a2bc867e5b4fc07265ca9be21c6</td>\n",
       "      <td>{'author_id': '3022979040', 'context_annotatio...</td>\n",
       "      <td>{'places': [{'full_name': 'New South Wales, Au...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1412189999055790080</td>\n",
       "      <td>2-ab62139e14adaf050ac13120deccbab6</td>\n",
       "      <td>{'author_id': '558259110', 'conversation_id': ...</td>\n",
       "      <td>{'places': [{'full_name': 'New South Wales, Au...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1412190244280012800</td>\n",
       "      <td>2-9c5c10bf0b52ed25d5707650cf77b128</td>\n",
       "      <td>{'author_id': '1158755742', 'conversation_id':...</td>\n",
       "      <td>{'places': [{'full_name': 'New South Wales, Au...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1412198117932371968</td>\n",
       "      <td>2-006aa665ed988fdb89bef231685f833a</td>\n",
       "      <td>{'author_id': '1348502962050535428', 'context_...</td>\n",
       "      <td>{'places': [{'full_name': 'Canberra, Australia...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>1412198454407794688</td>\n",
       "      <td>2-eec096a988dd97e133c574a1923ccdb7</td>\n",
       "      <td>{'author_id': '137315172', 'conversation_id': ...</td>\n",
       "      <td>{'places': [{'full_name': 'Canberra, Australia...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>1412185329184821248</td>\n",
       "      <td>1-1d7753f02dc586d1600b99652ad43426</td>\n",
       "      <td>{'author_id': '3306424254', 'conversation_id':...</td>\n",
       "      <td>{'places': [{'full_name': 'Canberra, Australia...</td>\n",
       "      <td>[{'id': 1412184603519971300, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>1412190755452424192</td>\n",
       "      <td>2-54b92b502587e83985f0a24b23a56037</td>\n",
       "      <td>{'author_id': '7598552', 'conversation_id': '1...</td>\n",
       "      <td>{'places': [{'full_name': 'Braddon, Canberra',...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>1412197569585848320</td>\n",
       "      <td>2-5eef29f3b507ee9b51f076dae89eb8f7</td>\n",
       "      <td>{'author_id': '1397010827048194048', 'conversa...</td>\n",
       "      <td>{'places': [{'full_name': 'Fyshwick, Canberra'...</td>\n",
       "      <td>[{'id': 1412189062442586000, 'tag': 'Australia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     _id                                _rev  \\\n",
       "0    1412193387575316480  2-0fa70896c4b97c5fa391af1b9ea8e0d1   \n",
       "1    1412195752344883200  1-1f2c1ed1b6971974f6cf160432cf5cd3   \n",
       "2    1412189452361891840  2-b7051a2bc867e5b4fc07265ca9be21c6   \n",
       "3    1412189999055790080  2-ab62139e14adaf050ac13120deccbab6   \n",
       "4    1412190244280012800  2-9c5c10bf0b52ed25d5707650cf77b128   \n",
       "..                   ...                                 ...   \n",
       "710  1412198117932371968  2-006aa665ed988fdb89bef231685f833a   \n",
       "711  1412198454407794688  2-eec096a988dd97e133c574a1923ccdb7   \n",
       "712  1412185329184821248  1-1d7753f02dc586d1600b99652ad43426   \n",
       "713  1412190755452424192  2-54b92b502587e83985f0a24b23a56037   \n",
       "714  1412197569585848320  2-5eef29f3b507ee9b51f076dae89eb8f7   \n",
       "\n",
       "                                                  data  \\\n",
       "0    {'author_id': '836119507173154816', 'conversat...   \n",
       "1    {'author_id': '1399941819950006272', 'conversa...   \n",
       "2    {'author_id': '3022979040', 'context_annotatio...   \n",
       "3    {'author_id': '558259110', 'conversation_id': ...   \n",
       "4    {'author_id': '1158755742', 'conversation_id':...   \n",
       "..                                                 ...   \n",
       "710  {'author_id': '1348502962050535428', 'context_...   \n",
       "711  {'author_id': '137315172', 'conversation_id': ...   \n",
       "712  {'author_id': '3306424254', 'conversation_id':...   \n",
       "713  {'author_id': '7598552', 'conversation_id': '1...   \n",
       "714  {'author_id': '1397010827048194048', 'conversa...   \n",
       "\n",
       "                                              includes  \\\n",
       "0    {'places': [{'full_name': 'Australia', 'geo': ...   \n",
       "1    {'places': [{'full_name': 'Australia', 'geo': ...   \n",
       "2    {'places': [{'full_name': 'New South Wales, Au...   \n",
       "3    {'places': [{'full_name': 'New South Wales, Au...   \n",
       "4    {'places': [{'full_name': 'New South Wales, Au...   \n",
       "..                                                 ...   \n",
       "710  {'places': [{'full_name': 'Canberra, Australia...   \n",
       "711  {'places': [{'full_name': 'Canberra, Australia...   \n",
       "712  {'places': [{'full_name': 'Canberra, Australia...   \n",
       "713  {'places': [{'full_name': 'Braddon, Canberra',...   \n",
       "714  {'places': [{'full_name': 'Fyshwick, Canberra'...   \n",
       "\n",
       "                                        matching_rules  \n",
       "0    [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "1    [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "2    [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "3    [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "4    [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "..                                                 ...  \n",
       "710  [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "711  [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "712  [{'id': 1412184603519971300, 'tag': 'Australia...  \n",
       "713  [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "714  [{'id': 1412189062442586000, 'tag': 'Australia...  \n",
       "\n",
       "[715 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073e3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
import json
import sys
import threading
import time
import heapq
import concurrent.futures
import numpy as np
from mpi4py import MPI
from collections import Counter

city_dict = {
    "1gsyd": "Greater Sydney",
    "2gmel": "Greater Melbourne",
    "3gbri": "Greater Brisbane",
    "4gade": "Greater Adelaide",
    "5gper": "Greater Perth",
    "6ghob": "Greater Hobart",
    "7gdar": "Greater Darwin"
}

state_mapping = {
    "New South Wales": "nsw",
    "Victoria": "vic",
    "Queensland": "qld",
    "Western Australia": "wa",
    "South Australia": "sa",
    "Tasmania": "tas",
    "Northern Territory": "nt",
    "Australian Capital Territory": "act"
}

gcc_dict = {}
person_data_dic = {}
author_ids = []


def countPersonTweet(tweet_data, author_ids):
    author_ids += [item['data']['author_id'] for item in tweet_data]


def matchState(val1, val2):
    abbreviation = state_mapping.get(val1)
    return abbreviation in val2 if abbreviation else False


def get_city_and_state(full_name):
    if ',' not in full_name:
        return None, None
    city_name, state_name = map(str.strip, full_name.split(','))
    return city_name, state_name


def match_city_and_state(city_name, state_name, key, sal_data):
    if '(' not in key:
        return key.lower() == city_name.lower()

    key_city_name, shorthand_state_name = key.split('(')
    key_city_name = key_city_name.strip().lower()
    shorthand_state_name = shorthand_state_name.strip(') ')

    if '-' in shorthand_state_name:
        shorthand_state_name = shorthand_state_name.split('-')[1].strip()

    return matchState(state_name, shorthand_state_name) and key_city_name == city_name.lower()


def countCity(gcc_dict, tweet_data, sal_data):
    for tweet in tweet_data:
        full_name = tweet['includes']['places'][0]['full_name']
        city_name, state_name = get_city_and_state(full_name)

        if not city_name or not state_name:
            continue

        for key, value in sal_data.items():
            if value['gcc'][1] == 'g' and match_city_and_state(city_name, state_name, key, sal_data):
                gcc = value['gcc']
                gcc_dict[gcc] = gcc_dict.get(gcc, 0) + 1
                break


def sort_dict_by_city(dic):
    sorted_dict = sorted(dic.items(), key=lambda x: (len(x[1]['city']), x[1]['tweets_num']), reverse=True)[:10]
    return sorted_dict


def get_city_name(location):
    if ',' not in location:
        return None
    city_name = location.split(',')[0].strip()
    return city_name


def find_gcc(city_name, sal_data):
    for key, value in sal_data.items():
        if value['gcc'][1] == 'g' and key.lower() == city_name.lower():
            return value['gcc'][1:]
    return None


def countPersonInCity(person_data_dic, tweet_data, sal_data):
    for tweet in tweet_data:
        author_id = tweet["data"]["author_id"]
        if author_id not in person_data_dic:
            person_data_dic[author_id] = {"tweets_num": 0, "city": {}}
        person_data_dic[author_id]["tweets_num"] += 1

        city_name = get_city_name(tweet['includes']['places'][0]['full_name'])
        if city_name is not None:
            valid_gcc = find_gcc(city_name, sal_data)
            if valid_gcc is not None:
                person_data_dic[author_id]["city"].setdefault(valid_gcc, 0)
                person_data_dic[author_id]["city"][valid_gcc] += 1


def printResult(gcc_dict, person_data_dic, author_ids):
    print(f"{'Greater Capital City':<40}{'Number of Tweets Made'}")
    sorted_gcc_dict = sorted(gcc_dict.items(), key=lambda x: x[1], reverse=True)
    for gcc, count in sorted_gcc_dict:
        city = city_dict[gcc]
        city_output = "{}({})".format(gcc, city)
        print("{:<40}{:<75}".format(city_output, count))

    print('-' * 50)

    sorted_data = sort_dict_by_city(person_data_dic)
    print("{:<5}{:<20}{:<40}".format("Rank", "Author Id", "Number of Unique City Locations and #Tweets"))
    for i, (author_id, value) in enumerate(sorted_data):
        city_info = ' '.join(["({}{})".format(value["city"][k], k) for k in value['city']])
        print("#{:<5}{:<20}{:<2}#{:<4} tweets - {}".format(i + 1, author_id, len(value["city"]), value["tweets_num"],
                                                           city_info))

    print('-' * 50)

    count_dict = Counter(author_ids)
    top_10 = heapq.nlargest(10, count_dict.items(), key=lambda x: x[1])

    print("{:<5}{:<20}{:<30}".format("Rank", "Author Id", "Number of Tweets Made"))
    for i, (id, count) in enumerate(top_10):
        print("#{:<5}{:<20}{:<30}".format(i + 1, id, count))

    print('-' * 50)


def my_pipeline(gcc_dict, person_data_dic, chunk, sal_data, author_ids):
    countCity(gcc_dict, chunk, sal_data)
    countPersonInCity(person_data_dic, chunk, sal_data)
    countPersonTweet(chunk, author_ids)


if __name__ == '__main__':

    node = int(sys.argv[1])
    core = int(sys.argv[2])
    data_path = sys.argv[3]
    sal_data_path = sys.argv[4]

    start_time = time.time()

    with open(data_path, 'r', encoding='utf-8') as f:
        tweet_data_total = json.load(f)

    with open(sal_data_path, 'r', encoding='utf-8') as f:
        sal_data = json.load(f)

    if node == 1:
        if core == 1:
            my_pipeline(gcc_dict, person_data_dic, tweet_data_total, sal_data, author_ids)
            printResult(gcc_dict, person_data_dic, author_ids)

        elif core == 8:
            total_records = len(tweet_data_total)
            records_per_thread = total_records // 8

            with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
                futures = []
                for i in range(8):
                    start_index = i * records_per_thread
                    length = records_per_thread if i < 7 else total_records - start_index

                    future = executor.submit(my_pipeline, gcc_dict, person_data_dic,
                                             tweet_data_total[start_index:start_index + length],
                                             sal_data, author_ids)
                    futures.append(future)

                for future in concurrent.futures.as_completed(futures):
                    result = future.result()

            printResult(gcc_dict, person_data_dic, author_ids)

    if node == 2 and core == 8:
        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()

        if rank == 0:
            tweet_data_chunk = tweet_data_total[:len(tweet_data_total) // 2]
        else:
            tweet_data_chunk = tweet_data_total[len(tweet_data_total) // 2:]

        thread_count = 4
        thread_blocks = [tweet_data_chunk[i::thread_count] for i in range(thread_count)]

        with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor:
            futures = []
            for i in range(2):
                future = executor.submit(my_pipeline, gcc_dict, person_data_dic, thread_blocks[i], sal_data, author_ids)
                futures.append(future)

            concurrent.futures.wait(futures)

            if rank == 0:
                comm.send((gcc_dict, person_data_dic, author_ids), dest=1)
            else:
                data = comm.recv(source=0)

                # combine results from both processes
                for key in data[0]:
                    if key in gcc_dict:
                        gcc_dict[key] += data[0][key]
                    else:
                        gcc_dict[key] = data[0][key]

                for key in data[1]:
                    if key in person_data_dic:
                        person_data_dic[key]['tweets_num'] += data[1][key]['tweets_num']
                        for k in data[1][key]['city']:
                            if k in person_data_dic[key]['city']:
                                person_data_dic[key]['city'][k] += data[1][key]['city'][k]
                            else:
                                person_data_dic[key]['city'][k] = data[1][key]['city'][k]
                    else:
                        person_data_dic[key] = data[1][key]

                author_ids += data[2]

                printResult(gcc_dict, person_data_dic, author_ids)

    end_time = time.time()
    print("elapsed time:", end_time - start_time)
