import json
import sys
import threading
import time
import heapq
import concurrent.futures
import numpy as np
from mpi4py import MPI
from collections import Counter

city_dict = {
    "1gsyd": "Greater Sydney",
    "2gmel": "Greater Melbourne",
    "3gbri": "Greater Brisbane",
    "4gade": "Greater Adelaide",
    "5gper": "Greater Perth",
    "6ghob": "Greater Hobart",
    "7gdar": "Greater Darwin"
}

state_mapping = {
    "New South Wales": "nsw",
    "Victoria": "vic",
    "Queensland": "qld",
    "Western Australia": "wa",
    "South Australia": "sa",
    "Tasmania": "tas",
    "Northern Territory": "nt",
    "Australian Capital Territory": "act"
}

gcc_dict = {}
person_data_dic = {}
author_ids = []


def countPersonTweet(tweet_data, author_ids):
    author_ids += [item['data']['author_id'] for item in tweet_data]


def matchState(val1, val2):
    abbreviation = state_mapping.get(val1)
    return abbreviation in val2 if abbreviation else False


def get_city_and_state(full_name):
    if ',' not in full_name:
        return None, None
    city_name, state_name = map(str.strip, full_name.split(','))
    return city_name, state_name


def match_city_and_state(city_name, state_name, key, sal_data):
    if '(' not in key:
        return key.lower() == city_name.lower()

    key_city_name, shorthand_state_name = key.split('(')
    key_city_name = key_city_name.strip().lower()
    shorthand_state_name = shorthand_state_name.strip(') ')

    if '-' in shorthand_state_name:
        shorthand_state_name = shorthand_state_name.split('-')[1].strip()

    return matchState(state_name, shorthand_state_name) and key_city_name == city_name.lower()


def countCity(gcc_dict, tweet_data, sal_data):
    for tweet in tweet_data:
        full_name = tweet['includes']['places'][0]['full_name']
        city_name, state_name = get_city_and_state(full_name)

        if not city_name or not state_name:
            continue

        for key, value in sal_data.items():
            if value['gcc'][1] == 'g' and match_city_and_state(city_name, state_name, key, sal_data):
                gcc = value['gcc']
                gcc_dict[gcc] = gcc_dict.get(gcc, 0) + 1
                break


def sort_dict_by_city(dic):
    sorted_dict = sorted(dic.items(), key=lambda x: (len(x[1]['city']), x[1]['tweets_num']), reverse=True)[:10]
    return sorted_dict


def get_city_name(location):
    if ',' not in location:
        return None
    city_name = location.split(',')[0].strip()
    return city_name


def find_gcc(city_name, sal_data):
    for key, value in sal_data.items():
        if value['gcc'][1] == 'g' and key.lower() == city_name.lower():
            return value['gcc'][1:]
    return None


def countPersonInCity(person_data_dic, tweet_data, sal_data):
    for tweet in tweet_data:
        author_id = tweet["data"]["author_id"]
        if author_id not in person_data_dic:
            person_data_dic[author_id] = {"tweets_num": 0, "city": {}}
        person_data_dic[author_id]["tweets_num"] += 1

        city_name = get_city_name(tweet['includes']['places'][0]['full_name'])
        if city_name is not None:
            valid_gcc = find_gcc(city_name, sal_data)
            if valid_gcc is not None:
                person_data_dic[author_id]["city"].setdefault(valid_gcc, 0)
                person_data_dic[author_id]["city"][valid_gcc] += 1


def printResult(gcc_dict, person_data_dic, author_ids):
    print(f"{'Greater Capital City':<40}{'Number of Tweets Made'}")
    sorted_gcc_dict = sorted(gcc_dict.items(), key=lambda x: x[1], reverse=True)
    for gcc, count in sorted_gcc_dict:
        city = city_dict[gcc]
        city_output = "{}({})".format(gcc, city)
        print("{:<40}{:<75}".format(city_output, count))

    print('-' * 50)

    sorted_data = sort_dict_by_city(person_data_dic)
    print("{:<5}{:<20}{:<40}".format("Rank", "Author Id", "Number of Unique City Locations and #Tweets"))
    for i, (author_id, value) in enumerate(sorted_data):
        city_info = ' '.join(["({}{})".format(value["city"][k], k) for k in value['city']])
        print("#{:<5}{:<20}{:<2}#{:<4} tweets - {}".format(i + 1, author_id, len(value["city"]), value["tweets_num"],
                                                           city_info))

    print('-' * 50)

    count_dict = Counter(author_ids)
    top_10 = heapq.nlargest(10, count_dict.items(), key=lambda x: x[1])

    print("{:<5}{:<20}{:<30}".format("Rank", "Author Id", "Number of Tweets Made"))
    for i, (id, count) in enumerate(top_10):
        print("#{:<5}{:<20}{:<30}".format(i + 1, id, count))

    print('-' * 50)


def my_pipeline(gcc_dict, person_data_dic, chunk, sal_data, author_ids):
    countCity(gcc_dict, chunk, sal_data)
    countPersonInCity(person_data_dic, chunk, sal_data)
    countPersonTweet(chunk, author_ids)


if __name__ == '__main__':

    node = int(sys.argv[1])
    core = int(sys.argv[2])
    data_path = sys.argv[3]
    sal_data_path = sys.argv[4]

    start_time = time.time()

    with open(data_path, 'r', encoding='utf-8') as f:
        tweet_data_total = json.load(f)

    with open(sal_data_path, 'r', encoding='utf-8') as f:
        sal_data = json.load(f)

    if node == 1:
        if core == 1:
            my_pipeline(gcc_dict, person_data_dic, tweet_data_total, sal_data, author_ids)
            printResult(gcc_dict, person_data_dic, author_ids)

        elif core == 8:
            total_records = len(tweet_data_total)
            records_per_thread = total_records // 8

            with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
                futures = []
                for i in range(8):
                    start_index = i * records_per_thread
                    length = records_per_thread if i < 7 else total_records - start_index

                    future = executor.submit(my_pipeline, gcc_dict, person_data_dic,
                                             tweet_data_total[start_index:start_index + length],
                                             sal_data, author_ids)
                    futures.append(future)

                for future in concurrent.futures.as_completed(futures):
                    result = future.result()

            printResult(gcc_dict, person_data_dic, author_ids)

    if node == 2 and core == 8:
        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()

        if rank == 0:
            tweet_data_chunk = tweet_data_total[:len(tweet_data_total) // 2]
        else:
            tweet_data_chunk = tweet_data_total[len(tweet_data_total) // 2:]

        thread_count = 4
        thread_blocks = [tweet_data_chunk[i::thread_count] for i in range(thread_count)]

        with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor:
            futures = []
            for i in range(2):
                future = executor.submit(my_pipeline, gcc_dict, person_data_dic, thread_blocks[i], sal_data, author_ids)
                futures.append(future)

            concurrent.futures.wait(futures)

            if rank == 0:
                comm.send((gcc_dict, person_data_dic, author_ids), dest=1)
            else:
                data = comm.recv(source=0)

                # combine results from both processes
                for key in data[0]:
                    if key in gcc_dict:
                        gcc_dict[key] += data[0][key]
                    else:
                        gcc_dict[key] = data[0][key]

                for key in data[1]:
                    if key in person_data_dic:
                        person_data_dic[key]['tweets_num'] += data[1][key]['tweets_num']
                        for k in data[1][key]['city']:
                            if k in person_data_dic[key]['city']:
                                person_data_dic[key]['city'][k] += data[1][key]['city'][k]
                            else:
                                person_data_dic[key]['city'][k] = data[1][key]['city'][k]
                    else:
                        person_data_dic[key] = data[1][key]

                author_ids += data[2]

                printResult(gcc_dict, person_data_dic, author_ids)

    end_time = time.time()
    print("elapsed time:", end_time - start_time)
